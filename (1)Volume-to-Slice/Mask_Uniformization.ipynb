{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64285cc",
   "metadata": {},
   "source": [
    "\n",
    "# Mask Uniformization & Slice-wise GIF Pipeline\n",
    "\n",
    "This notebook demonstrates **post-processing of fetal ultrasound slices**, including:\n",
    "\n",
    "- Tail extrapolation of skeletonized masks  \n",
    "- Uniform mask reconstruction (mask dilation from skeleton)  \n",
    "- Overlay visualization of original vs. uniformized masks  \n",
    "- Slice-wise GIF generation across time frames  \n",
    "- Batch mode for multiple case folders  \n",
    "\n",
    "> **Tip:** This notebook is GitHub-friendly. Users only need to set `ROOT_DIR` and `OUTPUT_DIR` to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07a3ef6",
   "metadata": {},
   "source": [
    "\n",
    "## Expected Folder Structure\n",
    "\n",
    "**Input:**\n",
    "\n",
    "```\n",
    "Root_Dataset/\n",
    "├── Case001/\n",
    "│   ├── time001/\n",
    "│   │   ├── image/         # original ultrasound images\n",
    "│   │   └── mask/          # raw binary masks (single-channel PNGs: 0/255)\n",
    "│   ├── time002/\n",
    "│   │   ├── image/\n",
    "│   │   └── mask/\n",
    "│   ...\n",
    "├── Case002/\n",
    "│   ├── time001/\n",
    "│   └── ...\n",
    "...\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```\n",
    "Processed_Dataset/\n",
    "├── Case001/\n",
    "│   ├── time001/\n",
    "│   │   ├── image/         # copied from original\n",
    "│   │   └── mask/          # uniformized masks\n",
    "│   ├── Uni_GIF/           # slice-wise GIF animations\n",
    "│   └── ...\n",
    "...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 📦 Imports\n",
    "import os, re, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt, label\n",
    "from skimage.morphology import skeletonize, disk, dilation, binary_opening\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d357e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Utility Functions\n",
    "\n",
    "def natural_key(s):\n",
    "    \"\"\"Sort helper that treats numeric parts as integers.\"\"\"\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', str(s))]\n",
    "\n",
    "def keep_largest_region(mask: np.ndarray):\n",
    "    \"\"\"Keep only the largest connected component in a binary mask.\"\"\"\n",
    "    labeled, num = label(mask)\n",
    "    if num == 0:\n",
    "        return mask\n",
    "    largest_label = np.argmax(np.bincount(labeled.flat)[1:]) + 1\n",
    "    return labeled == largest_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tail Extrapolation for Skeletons\n",
    "\n",
    "def extrapolate_tail(skel: np.ndarray, tail_frac=0.1):\n",
    "    \"\"\"\n",
    "    Extend the tail of the skeleton on both sides by line fitting.\n",
    "    Intuition: stabilize endpoints by fitting a short segment near the tail and extrapolating.\n",
    "    \"\"\"\n",
    "    h, w = skel.shape\n",
    "    pts = np.array(np.nonzero(skel)).T\n",
    "    if len(pts) == 0:\n",
    "        return skel.copy()\n",
    "    xs, ys = pts[:, 1], pts[:, 0]\n",
    "    x_mid = np.median(xs)\n",
    "    sides = [pts[xs <= x_mid], pts[xs > x_mid]]\n",
    "    out = skel.copy()\n",
    "    for side_pts in sides:\n",
    "        if len(side_pts) < 6:\n",
    "            continue\n",
    "        y_min, y_max = side_pts[:, 0].min(), side_pts[:, 0].max()\n",
    "        span = y_max - y_min\n",
    "        if span < 5:\n",
    "            continue\n",
    "        y_fit_low = y_max - 0.3 * span\n",
    "        y_fit_high = y_max - 0.1 * span\n",
    "        y_anchor = y_max - 0.2 * span\n",
    "        fit_mask = (side_pts[:, 0] >= y_fit_low) & (side_pts[:, 0] <= y_fit_high)\n",
    "        fit_pts = side_pts[fit_mask]\n",
    "        if len(fit_pts) < 3:\n",
    "            continue\n",
    "        y_fit = fit_pts[:, 0].astype(float)\n",
    "        x_fit = fit_pts[:, 1].astype(float)\n",
    "        A = np.vstack([y_fit, np.ones_like(y_fit)]).T\n",
    "        a, b = np.linalg.lstsq(A, x_fit, rcond=None)[0]\n",
    "        y_new = np.arange(int(round(y_anchor)), int(round(y_max)) + 1, dtype=int)\n",
    "        x_new = np.rint(a * y_new + b).astype(int)\n",
    "        x_new = np.clip(x_new, 0, w - 1)\n",
    "        out[y_new, x_new] = True\n",
    "    return skeletonize(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mask Uniformization from Skeleton\n",
    "\n",
    "def process_one(mask_bool: np.ndarray, open_r: int = 1):\n",
    "    \"\"\"\n",
    "    Pipeline for a single binary mask:\n",
    "    1) Keep largest component\n",
    "    2) Skeletonize\n",
    "    3) Tail extrapolation\n",
    "    4) Dilate skeleton by average half-thickness estimated via distance transform\n",
    "    5) Optional binary opening to smooth\n",
    "    Returns: (uniform_mask, skeleton)\n",
    "    \"\"\"\n",
    "    mask_bool = keep_largest_region(mask_bool)\n",
    "    skel = skeletonize(mask_bool)\n",
    "    skel = extrapolate_tail(skel, tail_frac=0.1)\n",
    "    dist = distance_transform_edt(mask_bool)\n",
    "    # Estimate half-thickness as mean distance at skeleton pixels\n",
    "    vals = dist[skel]\n",
    "    half = int(round(vals.mean())) if vals.size > 0 else 1\n",
    "    half = max(1, half)\n",
    "    uni = dilation(skel, disk(half))\n",
    "    if open_r > 0:\n",
    "        uni = binary_opening(uni, disk(open_r))\n",
    "    return uni, skel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64893889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Overlay Visualization\n",
    "\n",
    "def draw_contours(base_img, mask, color):\n",
    "    contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return cv2.drawContours(base_img, contours, -1, color, thickness=1)\n",
    "\n",
    "def overlay_visuals(time_dir: Path):\n",
    "    img_dir = time_dir / 'image'\n",
    "    mask_orig_dir = time_dir / 'mask'\n",
    "    mask_new_dir = time_dir / 'mask_uniform'\n",
    "    skel_dir = time_dir / 'mask_skel'\n",
    "\n",
    "    out_dir = time_dir / 'vis_mask_overlay'\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    images = sorted([p for p in img_dir.glob(\"*.png\")], key=lambda p: natural_key(p.name))\n",
    "    orig_masks = sorted([p for p in mask_orig_dir.glob(\"*.png\")]) if mask_orig_dir.exists() else []\n",
    "    new_masks = sorted([p for p in mask_new_dir.glob(\"*.png\")]) if mask_new_dir.exists() else []\n",
    "    skels = sorted([p for p in skel_dir.glob(\"*.png\")]) if skel_dir.exists() else []\n",
    "\n",
    "    for i, img_path in enumerate(images):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        if i < len(orig_masks):\n",
    "            img = draw_contours(img, cv2.imread(str(orig_masks[i]), cv2.IMREAD_GRAYSCALE) > 0, (0, 0, 255))  # red\n",
    "        if i < len(new_masks):\n",
    "            img = draw_contours(img, cv2.imread(str(new_masks[i]), cv2.IMREAD_GRAYSCALE) > 0, (0, 255, 0))    # green\n",
    "        if i < len(skels):\n",
    "            skel = cv2.imread(str(skels[i]), cv2.IMREAD_GRAYSCALE) > 0\n",
    "            yx = np.argwhere(skel)\n",
    "            for y, x in yx:\n",
    "                if 0 <= y < img.shape[0] and 0 <= x < img.shape[1]:\n",
    "                    img[y, x] = (0, 255, 255)  # yellow skeleton pixels\n",
    "        cv2.imwrite(str(out_dir / img_path.name), img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3918170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Slice-wise GIF Generation Across Time\n",
    "\n",
    "def generate_gifs(case_dir: Path, alpha: float = 0.5):\n",
    "    gif_dir = case_dir / 'Uni_GIF'\n",
    "    gif_dir.mkdir(parents=True, exist_ok=True)\n",
    "    time_dirs = sorted([d for d in case_dir.iterdir() if d.is_dir() and d.name.lower().startswith(\"time\")],\n",
    "                       key=lambda p: natural_key(p.name))\n",
    "    slice_dict = {}\n",
    "    for tdir in time_dirs:\n",
    "        img_dir = tdir / 'image'\n",
    "        mask_dir = tdir / 'mask_uniform'\n",
    "        if not img_dir.exists() or not mask_dir.exists():\n",
    "            continue\n",
    "        img_paths = sorted(img_dir.glob(\"*.png\"), key=lambda p: natural_key(p.name))\n",
    "        mask_paths = sorted(mask_dir.glob(\"*.png\"), key=lambda p: natural_key(p.name))\n",
    "        for i, (img_path, mask_path) in enumerate(zip(img_paths, mask_paths)):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None or mask is None:\n",
    "                continue\n",
    "            mask_colored = np.zeros_like(img)\n",
    "            mask_colored[:, :, 1] = 255  # green channel\n",
    "            overlay = img.copy()\n",
    "            overlay[mask > 0] = cv2.addWeighted(img[mask > 0], 0.7, mask_colored[mask > 0], 0.3, 0)\n",
    "            slice_dict.setdefault(i, []).append(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB))\n",
    "    for idx, frames in slice_dict.items():\n",
    "        gif_path = gif_dir / f'slice{idx:04d}.gif'\n",
    "        imageio.mimsave(gif_path, frames, duration=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da630604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main Processing\n",
    "\n",
    "def process_case(case_dir: Path, output_root: Path, open_radius: int = 1, alpha: float = 0.3, overwrite: bool = True):\n",
    "    time_dirs = sorted([d for d in case_dir.iterdir() if d.is_dir() and d.name.lower().startswith('time')],\n",
    "                       key=lambda p: natural_key(p.name))\n",
    "    print(f\"📂 Processing case: {case_dir.name} ({len(time_dirs)} time folders)\")\n",
    "    for tdir in time_dirs:\n",
    "        mask_dir = tdir / 'mask'\n",
    "        if not mask_dir.is_dir():\n",
    "            print(f\"Skip {tdir.name}: no mask folder\")\n",
    "            continue\n",
    "        masks = sorted(mask_dir.glob(\"*.png\"), key=lambda p: natural_key(p.name))\n",
    "        uni_dir = tdir / 'mask_uniform'\n",
    "        sk_dir = tdir / 'mask_skel'\n",
    "        if overwrite:\n",
    "            shutil.rmtree(uni_dir, ignore_errors=True)\n",
    "            shutil.rmtree(sk_dir, ignore_errors=True)\n",
    "        uni_dir.mkdir(parents=True, exist_ok=True)\n",
    "        sk_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for i, m_path in enumerate(masks):\n",
    "            m = cv2.imread(str(m_path), cv2.IMREAD_GRAYSCALE) > 0\n",
    "            uni, sk = process_one(m, open_r=open_radius)\n",
    "            cv2.imwrite(str(uni_dir / m_path.name), (uni.astype(np.uint8)) * 255)\n",
    "            cv2.imwrite(str(sk_dir / m_path.name), (sk.astype(np.uint8)) * 255)\n",
    "        overlay_visuals(tdir)\n",
    "\n",
    "    generate_gifs(case_dir, alpha=alpha)\n",
    "\n",
    "    # Copy processed images & masks to output_root\n",
    "    dst_case = output_root / case_dir.name\n",
    "    shutil.rmtree(dst_case, ignore_errors=True)\n",
    "    dst_case.mkdir(parents=True, exist_ok=True)\n",
    "    for tdir in time_dirs:\n",
    "        image_src = tdir / 'image'\n",
    "        mask_src = tdir / 'mask_uniform'\n",
    "        if not image_src.exists() or not mask_src.exists():\n",
    "            continue\n",
    "        dst_time = dst_case / tdir.name\n",
    "        (dst_time / 'image').mkdir(parents=True, exist_ok=True)\n",
    "        (dst_time / 'mask').mkdir(parents=True, exist_ok=True)  # renamed to mask/\n",
    "        # copy trees\n",
    "        for p in image_src.glob(\"*.*\"):\n",
    "            shutil.copy2(p, dst_time / 'image' / p.name)\n",
    "        for p in mask_src.glob(\"*.*\"):\n",
    "            shutil.copy2(p, dst_time / 'mask' / p.name)\n",
    "\n",
    "    print(f\"✅ Saved processed results to: {dst_case}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc313a67",
   "metadata": {},
   "source": [
    "\n",
    "## Run: Configure Paths and Start\n",
    "Set the paths below, then run the batch cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7700ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🔧 Configure your paths here\n",
    "ROOT_DIR = Path('/path/to/Root_Dataset')         # <-- change me\n",
    "OUTPUT_DIR = Path('/path/to/Processed_Dataset')  # <-- change me\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 🏃 Batch run\n",
    "if ROOT_DIR.exists():\n",
    "    for case in sorted(ROOT_DIR.iterdir()):\n",
    "        if case.is_dir():\n",
    "            process_case(case, OUTPUT_DIR, open_radius=1, alpha=0.3, overwrite=True)\n",
    "else:\n",
    "    print('⚠️ ROOT_DIR does not exist. Please set the correct path.')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
